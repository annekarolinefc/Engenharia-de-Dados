# Apache Spark

*    Ferramenta (em java) de processamento de **dados massivo** e de maneira distribuída.
*    Muito utilizada no **Big Data**

# PySpark

*    O PySpark é uma **biblioteca** Apache Spark
*    É uma ponte entre o Python e o Spark, isto é, utiliza-se os benefícios do Spark no código Python.

Estruturas de dados do Spark:
*    RDD
*    Data Frame

## RDD
Permite manipular usando funções de transformação (map, flatMap, filter, etc)
## DataFrame

Sempre que for executar o spark, precisa utilizar o spark context. Informa ao Python que haverá um objeto spark